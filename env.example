# LLM API Configuration
LLM_PROVIDER=deepseek  # Options: openai, deepseek, anthropic, azure, custom, local, etc.
LLM_API_KEY=your_api_key_here
LLM_API_URL=https://api.deepseek.com/v1/chat/completions
LLM_MODEL=deepseek-coder
MAX_CONCURRENT_REQUESTS=10

# Code Analysis Thresholds
MALICIOUS_THRESHOLD=0.7

# File Processing Settings
MAX_FILE_SIZE=1000000
SUPPORTED_EXTENSIONS=.py,.js,.ts,.php,.java,.c,.cpp,.cs,.go,.rb,.pl,.sh,.ps1,.json